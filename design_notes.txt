Block Size
---------------------------
- Transpose
  * Q6600 ran fast at 200 for 10k matrices.  didn't check higher
  * Pentium-M degrades performance slighly for 2k matrix.
  * Selected 60 as a compromise between Q6600 and pentium-m performance.
- Block Cholesky
  * 20 seems to be optimal, 60 slows it down a lot.



Block Cholesky Decomposition
---------------------------
The DenseMatrix64F based CholeskyDecompositionBlock class is easier to tune and offers equivalent
performance to BlockMatrix64F based BlockCholeskyOuter class. CholeskyDecompositionBlock achieves
optimal performance with munch smaller block sizes, but its performance actually degrades when
larger blocks that are optimal for BlockMatrix64F algorithms are used.  CholeskyDecompositionBlock
also works directly with DenseMatrix64F and avoids the need to convert matrix types.

Block matrix solver is much faster than the row-major solver.

However selecting the default class for Cholesky decomposition is not obvious because using
CholeskyDecompositionBlock would require an additional tuning parameter making the library
even more difficult to use.

Block QR Decomposition
--------------------------

Saving the W matrix instead of recomputing it each time was tried.  For smaller matrices it has
a noticeable speed improvement when solving.  Anything over 2k it seems to be negligible and almost double 
the memory required.  Block QR Decomposition is only used on larger matrices so there is no point in
saving W for later reuse when solving.

Block Matrix Multiply
---------------------------
- Block matrix multiplication does have fewer cache misses.
- Converting from row major to block and multiplying causes too many cache misses.
- Two different types of block matrix were created.
  * single continuous array
  * N*M arrays
- After making the code ugly and barely readable they had comparable performance to multReorder(),
  when multiplying two block matrices together.
- The code currently committed and that resides in experimental has
  not been optimized as much, but is readable.

Unrolled Matrix Multiplication
---------------------------
- Tried to unroll either a row or column in either of the inputs
- Does result in improve performance of small square matrices
- Does not always translate to tall or wide matrices
  * can be much slower than other orders
- Did not integrate into library because of added complexity

Combine matrix for DenseMatrix64
---------------------------
combine() is a function in SimpleMatrix that combines two matrices together and grows if needed.
No equivalent is directly provided in CommonOps since it is horribly memory inefficient.  Why
use DenseMatrix64 if you are going to do that.