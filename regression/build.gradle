dependencies {
	compile project(':main:autocode')
	compile project(':main:ejml-all')
	compile project(':main:ejml-cdense').sourceSets.benchmarks.output
	compile project(':main:ejml-ddense').sourceSets.benchmarks.output
	compile project(':main:ejml-dsparse').sourceSets.benchmarks.output
	compile project(':main:ejml-fdense').sourceSets.benchmarks.output
	compile project(':main:ejml-fsparse').sourceSets.benchmarks.output
	compile project(':main:ejml-zdense').sourceSets.benchmarks.output

	compile("com.peterabeles:regression:$auto64to32_version")
}

// Run the regression using a gradle command
// Currently this is the only way to get paths set up for benchmarks. See comment below.
//
// Example: ./gradlew runtimeRegression run --console=plain -Dexec.args="--SummaryOnly"
task runtimeRegression(type: JavaExec) {
	dependsOn build
	group = "Execution"
	description = "Run the mainClass from the output jar in classpath with ExecTask"
	classpath = sourceSets.main.runtimeClasspath
	main = "org.ejml.EjmlRuntimeRegressionApp"
	args System.getProperty("exec.args", "").split()
}

// Creating a jar would be easier to pass in arguments with, but it seems like only the first
// META-INF/BenchmarkList it sees is used. This limited the benchmarks to one module
